{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEh7gEJtLgNSpxwjFXWwN6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinnazim/esaa/blob/main/%ED%8C%8C%EB%A8%B8%EC%99%8408_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "​과제: 파이썬 머신러닝 완벽 가이드 ch8. 4\n",
        "\n",
        "p. 487 ~ 496"
      ],
      "metadata": {
        "id": "x_hVSXoiVjxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 텍스트 분류 실습 - 20 뉴스그룹 분류\n",
        "\n",
        "* 텍스트 분류: 특정 문서의 분류를 학습 데이터를 통해 학습해 모델을 생성한 뒤 이 학습 모델을 이용해 다른 문서의 분류를 예측하는 것\n",
        "\n",
        "* 이 절에서는 1, 2, 3 한꺼번에 수행\n",
        "1. 카운트 기반과 TF-IDF 기반의 벡터화를 차례로 적용해 예측 성능 비교\n",
        "2. 피처 벡터화를 위한 파라미터와 그리드서치CV 기반의 하이퍼 파라미터 튜닝\n",
        "3. 사이킷런의 Pipeline 객체를 통해 피처 벡터화 파라미터와 그리드서치 CV 기반의 하이퍼 파라미터 튜닝\n",
        "\n",
        "### 텍스트 정규화"
      ],
      "metadata": {
        "id": "Y51YzC82Vud3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe-J9rvwVbKi",
        "outputId": "37238179-9afa-40a8-d9bc-75383d3ba3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "news_data = fetch_20newsgroups(subset = 'all', random_state = 156)\n",
        "\n",
        "print(news_data.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print('target 클래스의 값과 분포도 \\n', pd.Series(news_data.target).value_counts().sort_index())\n",
        "print('target 클래스의 이름들 \\n', news_data.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXLivBr9V4go",
        "outputId": "1c8e02e6-d677-489a-cce7-2d111805b921"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target 클래스의 값과 분포도 \n",
            " 0     799\n",
            "1     973\n",
            "2     985\n",
            "3     982\n",
            "4     963\n",
            "5     988\n",
            "6     975\n",
            "7     990\n",
            "8     996\n",
            "9     994\n",
            "10    999\n",
            "11    991\n",
            "12    984\n",
            "13    990\n",
            "14    987\n",
            "15    997\n",
            "16    910\n",
            "17    940\n",
            "18    775\n",
            "19    628\n",
            "dtype: int64\n",
            "target 클래스의 이름들 \n",
            " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_data.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6XNJK3JV4eg",
        "outputId": "9bcbefd4-5308-4a4e-aff6-4d3474b22973"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
            "Subject: Re: Observation re: helmets\n",
            "Organization: Sun Microsystems, RTP, NC\n",
            "Lines: 21\n",
            "Distribution: world\n",
            "Reply-To: egreen@east.sun.com\n",
            "NNTP-Posting-Host: laser.east.sun.com\n",
            "\n",
            "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
            "> \n",
            "> The question for the day is re: passenger helmets, if you don't know for \n",
            ">certain who's gonna ride with you (like say you meet them at a .... church \n",
            ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
            ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
            ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
            ">passenger? \n",
            "\n",
            "If your primary concern is protecting the passenger in the event of a\n",
            "crash, have him or her fitted for a helmet that is their size.  If your\n",
            "primary concern is complying with stupid helmet laws, carry a real big\n",
            "spare (you can put a big or small head in a big helmet, but not in a\n",
            "small one).\n",
            "\n",
            "---\n",
            "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
            "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
            "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
            " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 개별 데이터가 텍스트로 어떻게 구성돼 있는지 데이터 한 개 추출한 값\n",
        "* 뉴스그룹 제목\n",
        "* 작성자\n",
        "* 소속\n",
        "* 이메일 등\n",
        "\n",
        "### 내용을 제외하고 제목 등의 다른 정보 제거할 것"
      ],
      "metadata": {
        "id": "qJqQbJPtdNze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# subset='train'으로 학습용 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
        "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'),\n",
        "                   random_state=156)\n",
        "X_train = train_news.data\n",
        "y_train = train_news.target\n",
        "\n",
        "# subset='test'으로 테스트 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
        "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\n",
        "                   random_state=156)\n",
        "X_test = test_news.data\n",
        "y_test = test_news.target\n",
        "print('학습 데이터 크기 {0}, 테스트 데이터 크기 {1}'.format(len(train_news.data), len(test_news.data)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_lvpWJNV4cy",
        "outputId": "efac12b7-ba3c-47ab-86bc-5697040238fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 크기 11314, 테스트 데이터 크기 7532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 피처 벡터화 변환과 머신러닝 모델 학습/예측/평가\n",
        "\n",
        "* 학습: 11314개의 뉴스그룹 문서가 리스트 형태로 주어짐\n",
        "* 테스트: 7532개의 문서가 리스트 형태로 주어짐"
      ],
      "metadata": {
        "id": "CGYCmI5ydiTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectorization으로 피처 벡터화 변환 수행.\n",
        "cnt_vect = CountVectorizer()\n",
        "cnt_vect.fit(X_train)\n",
        "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
        "\n",
        "# 학습 데이터로 fit()된 CountVectorizer를 이용해 체스트 데이터를 피터 벡처화 변환 수행.\n",
        "X_test_cnt_vect= cnt_vect.transform(X_test)\n",
        "\n",
        "print('학습 데이터 텍스트의 countVectorizer shape:', X_train_cnt_vect.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DSTCCU0V4bW",
        "outputId": "19f76c36-4612-4abf-d612-b0c8eaa3d726"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 텍스트의 countVectorizer shape: (11314, 101631)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> fit_transform 대신 cnt_vect.transform을 사용하면 안되는 이유: 학습 시 사용된 피처 개수와 예측 시 사용할 피처 개수 달라짐"
      ],
      "metadata": {
        "id": "DOCYyviJdyWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# LogisticRegression을 이용해 학습/예측/평가 수행.\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_cnt_vect, y_train)\n",
        "pred= lr_clf.predict(X_test_cnt_vect)\n",
        "print('CountVectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2cKO4a0V4ZF",
        "outputId": "6097f9ac-ed80-40a3-b47f-ce8f53d1e585"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorized Logistic Regression의 예측 정확도는 0.606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#TF-IDF 벡터화를 적용해 학습 데이터 세트와 테스트 데이터 세트 변환.\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
        "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
        "\n",
        "#LogisticRegression을 이용해 학습/예측/평가 수행\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
        "pred= lr_clf.predict(X_test_tfidf_vect)\n",
        "print('TF-IDF Logistic Regression의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frGrJggFV4XI",
        "outputId": "45a51759-fa78-45c2-bf63-8965d906947a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Logistic Regression의 예측 정확도는 0.674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> TF_IDF가 단순 카운트 기반보다 훨씬 높은 예측 정확도를 제공함, 텍스트 분석에서 좋은 예측 결과 도출\n",
        "\n",
        "* 텍스트 분석에서 머신러닝 모델 성능 향상시키는 방법\n",
        "  * 최적의 ML 알고리즘 선택\n",
        "  * 최상의 피처 전처리 수행"
      ],
      "metadata": {
        "id": "6JnVgeOjeS3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300) 변경 후 예측 성능 재측정"
      ],
      "metadata": {
        "id": "xXWzfJvCexC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words 필터링을 추가하고 ngram을 기본 (1,1)에서 (1,2)로 변경해 피처 벡터화 적용\n",
        "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)\n",
        "tfidf_vect.fit(X_train)\n",
        "X_train_tfidt_vect = tfidf_vect.transform(X_train)\n",
        "X_test_tfidt_vect = tfidf_vect.transform(X_test)\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_tfidt_vect, y_train)\n",
        "pred = lr_clf.predict(X_test_tfidt_vect)\n",
        "print('TF-IDF Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzHEsWwFV4Ux",
        "outputId": "5a85e6af-4936-4fb0-c8a0-8991d515b601"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Logistic Regression의 예측 정확도는 0.692246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 하이퍼 파라미터 수행"
      ],
      "metadata": {
        "id": "ZyY_Wip_fuxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 최적 C값 도출 튜닝 수행. CV는 3폴드 세트로 설정\n",
        "params = { 'C':[0.01, 0.1, 1, 5, 10]}\n",
        "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv_lr.fit(X_train_tfidt_vect, y_train)\n",
        "print('Logistic Regression best C parameter :', grid_cv_lr.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUHp4cXeV4Rc",
        "outputId": "8b1ccee6-b13f-41f9-ac07-8437003adc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적 C값으로 학습된 grid_cv로 예측 및 정확도 평가\n",
        "pred = grid_cv_lr.predict(X_test_tfidt_vect)\n",
        "print('TF-IDF Vectorized Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))\n",
        ""
      ],
      "metadata": {
        "id": "df-s37JmWJCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 로지스틱 회귀 C가 10일때, 교차 검증 테스트 세트에서 가장 좋은 예측 성능을 나타냄"
      ],
      "metadata": {
        "id": "5sKHaoYGfzxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사이킷런의 Pipeline 사용 및 GridSearchCV와의 결합\n",
        "\n",
        "* Pipeline 클래스\n",
        "  * 피처벡터화\n",
        "  * ML 알고리즘 학습, 예측을 위한 코드 작성\n",
        "  * 대용량 데이터의 피처 벡터화 결과를 별도 데이터로 저장하지 않고 스트림 기반에서 바로 ML 알고리즘의 데이터로 입력할 수 있기에 수행 시간 절약\n",
        "  * 모든 데이터 전처리작업+Estimater 결합 가능"
      ],
      "metadata": {
        "id": "QB0latyuf5XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# TfidVectorizer 객체를 tfid_vect로, LogisticRegression 객체를 lr_clf로 생성하는 Pipeline 생성\n",
        "pipeline=Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)),\n",
        "    ('lr_clf', LogisticRegression(C=10))\n",
        "])\n",
        "\n",
        "# 별도의 TfidfVectorizer 객체의 fit(), transform()과 LogisticRegression의 fit(), predict()가 필요없음\n",
        "# pipeline의 fit과 predict()만으로 한꺼번에 피처 벡터화와 ML 학습/예측이 가능\n",
        "pipeline.fit(X_train, y_train)\n",
        "pred = pipeline.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:3f}'.format(accuracy_score(y_test, pred)))\n",
        ""
      ],
      "metadata": {
        "id": "Imc-RLsDWMDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "pipeline=Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
        "    ('lr_clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Pipeline에 기술된 각각의 객체 변수에 언더바(__) 2개를 연달아 붙여 GridSearchCV에 사용될 파라미터/하이퍼파라미터 이름과 값을 설정\n",
        "params = {'tfidf_vect__ngram_range':[(1,1),(1,2),(1,3)],\n",
        "         'tfidf_vect__max_df': [100,300,700],\n",
        "         'lr_clf__C':[1,5,10]}\n",
        "\n",
        "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
        "grid_cv_pipe = GridSearchCV(pipeline, param_grid=params, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_cv_pipe.fit(X_train, y_train)\n",
        "print(grid_cv_pipe.best_params_, grid_cv_pipe.best_score_)\n",
        "\n",
        "pred = grid_cv_pipe.predict(X_test)\n",
        "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}.format(accuracy_score(y_test,pred))')\n",
        ""
      ],
      "metadata": {
        "id": "D46ELOO_WMBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}